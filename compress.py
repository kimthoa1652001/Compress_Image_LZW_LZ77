# -*- coding: utf-8 -*-
"""Compress.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14QCWBNJv1jjHLaWwkz9m6AsF8sagoT7R
"""

import re
import numpy as np
from PIL import Image,ImageOps
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow
import time
import cv2 as cv2
import os
import io
import sys
import pandas as pd

def get_image_values(path,g,name):
  image = Image.open(path)
  if g == 0:
    image = ImageOps.grayscale(image)
  my_string = np.asarray(image,np.uint8)
  shape = my_string.shape
  print(shape)
  a = my_string
  my_string = my_string.reshape(-1)
  my_string = my_string.tolist()
  my_string = [str(x) for x in my_string]
  
  output = open(name,"w+")
  output.write(str(my_string))
  size_def = os.path.getsize('/content/'+name)
  return my_string,image,shape,a,size_def

def image_decode(uncompressed_string,shape,a):
  res = list(map(int, uncompressed_string))
  res = np.array(res)
  res = res.astype(np.uint8)
  res = np.reshape(res, shape)
  print(type(res))
  print("Observe the shapes and input and output arrays are matching or not")
  print("Input image dimensions:",shape)
  print("Output image dimensions:",res.shape)
  data = Image.fromarray(res)
  #data.save(name)
  if a.all() == res.all():
      print("Success")
  return data

"""# Huffman Encoding-Decoding

## Pre Processing
"""

def pre_process(my_string):
  letters = []
  only_letters = []
  for letter in my_string:
    if letter not in letters:
        frequency = my_string.count(letter)             #frequency of each letter repetition
        letters.append(frequency)
        letters.append(letter)
        only_letters.append(letter)

  nodes = []
  while len(letters) > 0:
    nodes.append(letters[0:2])
    letters = letters[2:]                               # sorting according to frequency
  nodes.sort()
  huffman_tree = []
  huffman_tree.append(nodes)
  return nodes,huffman_tree,only_letters

def combine_nodes(nodes,huffman_tree):
    pos = 0
    newnode = []
    if len(nodes) > 1:
        nodes.sort()
        nodes[pos].append("1")                       # assigning values 1 and 0
        nodes[pos+1].append("0")
        combined_node1 = (nodes[pos] [0] + nodes[pos+1] [0])
        combined_node2 = (nodes[pos] [1] + nodes[pos+1] [1])  # combining the nodes to generate pathways
        newnode.append(combined_node1)
        newnode.append(combined_node2)
        newnodes=[]
        newnodes.append(newnode)
        newnodes = newnodes + nodes[2:]
        nodes = newnodes
        huffman_tree.append(nodes)
        combine_nodes(nodes,huffman_tree)
    return huffman_tree

def print_tree(huffman_tree):
  checklist = []
  for level in huffman_tree:
    for node in level:
        if node not in checklist:
            checklist.append(node)
        else:
            level.remove(node)
  return checklist

def generate_code(only_letters,checklist,my_string):
  letter_binary = []
  if len(only_letters) == 1:
    letter_code = [only_letters[0], "0"]
    letter_binary.append(letter_code*len(my_string))
  else:
    for letter in only_letters:
        code =""
        for node in checklist:
            if len (node)>2 and letter in node[1]:           #genrating binary code
                code = code + node[2]
        lettercode =[letter,code]
        letter_binary.append(lettercode)

  bitstring =""
  for character in my_string:
    for item in letter_binary:
        if character in item:
            bitstring = bitstring + item[1]
  return letter_binary, bitstring

def decode(bitstring,letter_binary): 
  uncompressed_string = []
  code =""
  for digit in bitstring:
    code = code+digit
    pos=0                                        #iterating and decoding
    for letter in letter_binary:
        if code ==letter[1]:
            uncompressed_string.append(letter_binary[pos] [0])
            code=""
        pos+=1
  return uncompressed_string

def process_huff(path,g,name_string,name_encode):
  my_string,image,shape,a,size_def = get_image_values(path,g,name_string) 
  print("Your original file size was", size_def)

  s = time.time()
  nodes,huffman_tree,only_letters = pre_process(my_string)
  new_node = combine_nodes(nodes,huffman_tree)
  huffman_tree.sort(reverse = True)
  checklist = print_tree(huffman_tree)
  letter_binary, bitstring = generate_code(only_letters,checklist,my_string)
  print(letter_binary)
  e = time.time()
  print('Time for ecoding image: ',e-s)
  output = open(name_encode,"w+")
  output.write(bitstring)
  size_encode = os.path.getsize('/content/'+name_encode)
  print("Compression size: ",size_encode)
  print("Compression ratio: ",size_def/size_encode)

  start = time.time()
  uncompressed_string = decode(bitstring,letter_binary)
  end = time.time()
  #print(uncompressed_string)
  print('Time for decoding: ',end-start,'s')

  img_de = image_decode(uncompressed_string,shape,a)
  

  show = np.hstack((image,img_de))
  cv2_imshow(show)

"""## Gray-Image

## Color Image

# LZW
"""

def compress(uncompressed):
    # Build the dictionary.
    dict_size = 256
    dictionary = dict((str(i), i) for i in range(dict_size))
    
    current_reg = ""
    result = []
    for pixel in uncompressed:
        if current_reg =="":
          dic_entry = pixel
        else:
          dic_entry = current_reg + '-' + pixel
        #print('dic_entry',dic_entry)

        if dic_entry in dictionary:
            current_reg = dic_entry
        else:
            #print('current_reg',current_reg)
            result.append(dictionary[current_reg])
            # Add wc to the dictionary.
            dictionary[dic_entry] = dict_size
            #print("dict_size:",dict_size,"dict_",dic_entry)
            dict_size += 1
            current_reg = pixel
        
    if current_reg:
        result.append(dictionary[current_reg])
    return result

dictionary = dict((i, str(i).split()) for i in range(255))

dictionary

def decompress(compressed):  
 
    # Build the dictionary.
    dict_size = 256
    dictionary = dict((i, str(i).split()) for i in range(dict_size))
 
    result = []
    w = []
    w.append(str(compressed.pop(0)))
    result.extend(w)

    for k in compressed:
        entry = []
        if k in dictionary:
            entry = dictionary[k]
          
        elif k == dict_size:
            entry.extend(w)
            entry.append(w[0])

        else:
            raise ValueError('Bad compressed k: %s' % k)
        result.extend(entry)
 
        # Add w+entry[0] to the dictionary.
        #print(w,type(entry[0]))
        dictionary[dict_size] = [i for i in w ]
        dictionary[dict_size].append(entry[0])
        #print("dict_size:",dict_size,"dict_",dictionary[dict_size])
        
        dict_size += 1
        w = entry
    
    return result

def compressing_and_decompressing(string,shape,a,size_def,name_encode):
    s = time.time()
    compressed = compress(string)
    e = time.time()
    print("Time for compressed: ",e-s)
    #
    output = open(name_encode,"w+")
    output.write(str(compressed))
    size = os.path.getsize('/content/'+name_encode)
    print("Compression size: ",size)

    s = time.time()
    decompressed = decompress(compressed)
    e = time.time()
    print("Time for decompressed: ",e-s)

    print("Compression ratio: ",size_def/size)
    print("\n")

    print ("COMPARE:")
    if string == decompressed:
        print("Successfully Done")

    else:
        print("Not done!")
        print("\n")

    img_decode = image_decode(decompressed,shape,a)

    return img_decode

def process_lzw(path,g,name_string,name_encode):
    values,image,shape,a,size_def = get_image_values(path,g,name_string) 
    print("Your original file size was", size_def)

    img = compressing_and_decompressing(values,shape,a,size_def,name_encode)
    show = np.hstack((image,img))
    cv2_imshow(show)

"""## Color Image"""

process_lzw('/content/meo.jfif',1,'string_default.txt','lzw_compress.txt')

"""## Gray Image"""

process_lzw('/content/tree-736885__480.jpeg',0,'string_default_1.txt','lzw_compress_1.txt')

"""# LZ77"""

def encode_(text,window_size,lookahead_buffer_size):
  search_buffer_size = window_size - lookahead_buffer_size
  text.append('')
  id_left_search = 0
  encodedNumbers = []
  encodedSizes = []
  encodedLetters = []
  id_right_search = 0
  encoded = 0
  while id_right_search<len(text):
    while id_left_search+search_buffer_size>=encoded:
      #current = text[id_left_search:id_right_search] #encoded
      #look_text = text[id_right_search:lookahead_buffer_size+id_right_search]

      i = id_right_search
      same_id = []
      offset = [] #id same
      for j in range(id_left_search,id_right_search):
        if text[j] == text[i]:
          same_id.append(j)
          offset.append(i-j)
      if len(same_id)==0 or (id_left_search==id_right_search):  #no match
        encodedNumbers.append(0)
        encodedSizes.append(0)
        encodedLetters.append(text[i])
        id_right_search+=1
        encoded +=1
      else:
        mxMatch = 0
        mxBack = 0
        for k in range(len(same_id)):
          lenght = 0
          for it in range(same_id[k],id_right_search+lookahead_buffer_size):
            #print(it,i)
            if text[it]==text[i]:
              lenght+=1
              i+=1
              if (i>=i+lookahead_buffer_size) or (i>=len(text)):
                i = id_right_search
                break
            else:
              i = id_right_search
              break
          if lenght>=mxMatch:
            mxMatch =lenght
            mxBack = offset[k]
        encodedNumbers.append(mxBack)
        encodedSizes.append(mxMatch)
        encodedLetters.append(text[id_right_search+mxMatch])
        encoded=encoded+mxMatch+1
    
        id_right_search = id_right_search+mxMatch+1
        if id_right_search>=len(text):
          break
        #print('_',id_right_search)

    id_left_search = encoded - search_buffer_size
    #print('left',id_left_search)
  return encodedNumbers, encodedSizes, encodedLetters

def decode_lz77(encodedNumbers, encodedSizes, encodedLetters):
    i = 0
    decodedString = []
    while i < len(encodedNumbers):
        if (encodedNumbers[i] == 0):
            decodedString.append(encodedLetters[i])
        else:
            currentSize = len(decodedString)
            for j in range(0, encodedSizes[i]):
                decodedString.append(decodedString[currentSize-encodedNumbers[i]+j])
            decodedString.append(encodedLetters[i])
        i = i+1
    return decodedString

windownSize = 1000
lookaheadBuffer = 500

def process_lz77(path,g,name_string,name_encode):
 
  my_string,image,shape,a,size_def = get_image_values(path,g,name_string)
  print("Your original file size was", size_def) 
  s = time.time()
  [encodedNumbers, encodedSizes, encodedLetters] = encode_(my_string, windownSize, lookaheadBuffer)
  e = time.time()
  for i in range(24):
    print('<',encodedNumbers[i], encodedSizes[i], encodedLetters[i],'>', end='')

  result =[encodedNumbers, encodedSizes, encodedLetters]
  output = open(name_encode,"w+")
  output.write(str(result))
  size_en = os.path.getsize('/content/'+name_encode)
  print("Time for encode: ",e-s)
  print("Encode size: ",size_en)
  print("Compression ratio: ",size_def/size_en)
  
  s = time.time()
  decodedString = decode_lz77(encodedNumbers, encodedSizes, encodedLetters)
  e = time.time() 

  if my_string == decodedString:
    print("Decode Success")
  #elif my_string == decodedString.pop(len(decodedString)-1):
  #  print("Decode Success")
  print("Time for decode: ",e-s)
  decodedString.pop(len(decodedString)-1)
  img = image_decode(decodedString,shape,a)
  show = np.hstack((image,img))
  cv2_imshow(show)

"""## Gray Image"""

process_lz77('/content/dog.jpg',0,'String_def_lz77.txt','Lz77_3.txt')

"""## Color Image"""

process_lz77('/content/px142077-image-kwvvvktc.jpeg',1,'String_def_lz77_1.txt','Lz77_2.txt')

"""## Nhận xét sơ bộ

*   Time: LZW cho thời gian nén khá nhanh, còn LZ77 thời gian nén tùy thuộc vào windownSize, và Lookbuffer nhưng nhìn chung thời gian nén chậm hơn vì thuật toán Lz77 phức tạp hơn LZW, nhưng đặc biệt thời gian giải nén của Lz77 nhanh hơn rất nhiều LZW.
*   Tỷ lệ nén: Tùy vào việc lựa chọn param cho Lz77 mà tỷ lệ nén sẽ càng cao nhưng đồng thời thời gian cũng tăng, Lzw cho ra tỷ lệ nén so với Lz77 nhìn chung ổn trên ảnh màu, trên ảnh xám tỷ lệ nén của Lz77 tốt hơn so với Lzw.

*   Sẽ test thêm ảnh trên các kích thước khác nhau để xem phụ thuộc vào size ảnh thì thuật toán nào hiệu quả?
*   Test thêm trên các loại ảnh khác nhau như tif, gif, jpeg, png??

Thoa ơi tui muốn có 1 bảng đánh giá với hàng là cái tiêu chí và cột là các thuật toán nén

Đánh giá càng nhiều càng tốt nha
"""